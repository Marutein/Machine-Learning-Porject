---
title: "Mahcine Learning Final Project"
subtitle: "Predicting Orange Juice Purchase"
author: "Gary Buckley and Ivan Espino"
output: pdf_document
date: "2022-11-03"
---

# Problem Statement

The Orange Juice Category presents a significant opportunity for our firm. We sell two brands of orange juice to our customers: Citrus Hill (CH) and Minute Maid (MM). Our company makes higher margins on MM orange juice than CH, so the higher percentage of customers that buy MM, the more profit we will make.

How do we know who will buy MM orange juice? There are two layers to this question. First, we need to explore what factors cause (or are at least correlated with) customers to buy MM over CH. Answering this question allows us to target our advertising to these customers, position our brand to attract these types of buyers, and other possible strategies to improve our margin in the orange juice category. 

The second question is can we predict who will buy MM over CH? This is similar to question 1, but goes a bit further. Question 1 is a descriptive analysis - figuring our what influenced buyers to purchase MM in the past. This second question is a predictive analysis: if a new customer walks into our store, we want to predict how likely they are to purchase MM. The results from question 1 and 2 work together. If we know what factors influence people to buy MM, we can adjust our strategy accordingly. Then, if we can predict purchase behavior, we can predict the influence of the new strategy on our revenue. This allows us to run a cost-benefit analysis and determine if the strategy is worthwhile.

To answer these questions, we have collected 1070 purchases in which the customer purchased orange juice. Note that we are limiting ourselves to the population of consumsers that buy orange juice. We are NOT finding what causes a customer to buy or not buy orange juice. Instead, we are finding what causes a customer who is purchasing orange juice to choose MM over CH. 

As a result of our analysis, the brand manager can expect us to identify the factors that most strongly influence whether a customer purchases MM or not. In addition, the sales manager can expect a model that will predict whether a customer will purchase MM or CH along with the expected performance of the model.

#Methods

```{r, warning=FALSE,library}
#Libraries used
library(dplyr)
library(plotROC)
library(ggplot2)
library(caret)
library(performance)
library(car)
library(ROCR)
library(glmnet)
library(corrplot)
library(AICcmodavg)
library(plotROC)
```

We start by pulling and preparing our data

```{r, data}
#Data set
df<-read.csv(url("http://data.mishra.us/files/project/OJ_data.csv"))
#ensure all predictors are numeric
df[2:14] <- lapply(df[2:14], as.numeric)
#code target as factor since it is binary
df$Purchase <- as.factor(df$Purchase)
glimpse(df)
head(df)
```

**Logistic Regression**

We begin by building a logistic regression model. The advantage of regression models is that they clearly measure the impact of a factor on our target variable. We run a logistic regression since our target variable is binary. This model will help us evaluate which factors are the most important influencers of purchase behavior. 

The data is coded such that CH is labeled as 1 and MM as 0. We will swtich these since we want to model whether the customer purchased MM.

```{r}
#Switching Purchase values: 0 to 1 = MM Purchased and 1 to 0 = MM No Purchased.
#A factor with levels 0 and 1 indicating whether the customer purchased Citrus Hill (1) or Minute Maid Orange Juice (0).

df <- df %>%
  mutate(across(Purchase, ~ case_when(. == 0 ~ "Yes",
                                        . == 1 ~ "No",
                                        TRUE ~ NA_character_)))
df <- df %>%
      mutate(Purchase = ifelse(Purchase == "No",0,1))

head(df)
```

We'd like to evaluate the predictive power of this model. To do so, we must hold out some of the data so we can test our model on it. We will keep 70% of our data to train the model and use 30% to test it.

```{r}
#Splitting the data into Train, Test
split = 0.7
set.seed(1234)

train.data <- sample(1:nrow(df), split * nrow(df))
test.data <- setdiff(1:nrow(df), train.data)

train.data <- df[train.data,]
test.data <- df[test.data,]
```

```{r}
predictors <- train.data[,c(-1)]
purchase <- train.data$Purchase
```


```{r}
# Checking for multicollinearity and plotting correlations between predictors
correlation = cor(train.data)
correlation
corrplot.mixed(correlation, lower.col = "black", tl.cex=.7,number.cex = .7)
```

```{r}
#Logistic Model
predictionModel1 <- glm(Purchase ~ ., data = train.data,family=binomial(link='logit'))
summary(predictionModel1)

#Dropping predictors variables perfectly correlated
drop <- c("SalePriceCH", "SalePriceMM", "ListPriceDiff","PriceDiff")
train.data = train.data[,!(names(train.data) %in% drop)]

predictionModel <- glm(Purchase ~ ., data = train.data, family=binomial(link='logit'))
summary(predictionModel)

# Calculating VIF for each of the predictors
vif(predictionModel)
```

```{r}
#Examining predictors quality using LASSO
predictors <-data.matrix(predictors)
set.seed(1234)

cv.binomial <- cv.glmnet(x = predictors, y = purchase,
alpha=1, family="binomial",
nfolds=4, standardize = TRUE, type.measure = "auc")
plot(cv.binomial)

#AUC = over 90% of the time the model will classify YES and NO correctly. 
```

```{r}
#Applying shrinkage parameter λ
(best.lambda <- cv.binomial$lambda.min)
y4<- coef(cv.binomial, s="lambda.min", exact=FALSE)
print(y4)
```

```{r}
#Optimal value of λ in the test data
test.predictors <- data.matrix(test.data[,c(-1)])
actual <- test.data$Purchase
pred.model = predict(cv.binomial, newx = test.predictors, type = "response",s ="lambda.min")

pred <- prediction(pred.model, test.data$Purchase)
perf <- performance(pred,"tpr","fpr")
auc_ROCR <- performance(pred,measure ="auc")

# plot ROC curve
plot(perf,colorize=FALSE, col="black") 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
text(1,0.15,labels=paste("AUC = ",round(auc_ROCR@y.values[[1]],
                                        digits=2),sep=""),adj=1)
```

```{r}
#new DF excluding betas less important
drop <- c("PriceCH","PriceMM", "DiscCH", "DiscMM", "SpecialCH", "SalePriceMM","PctDiscMM","ListPriceDiff")
new.df = df[,!(names(df) %in% drop)]
#creating a new DF 
new.df
```

```{r}
#Splitting data
split = 0.7
set.seed(1234)


train_index <- sample(1:nrow(new.df), split * nrow(new.df))
test_index <- setdiff(1:nrow(new.df), train_index)

train_data <- new.df[train_index,]
test_data <- new.df[test_index,]
```

```{r}
#Learning relationship between predictor variables and the outcome variables using train data set
predictionModel <- glm(Purchase ~ ., data = train_data,family=binomial(link='logit'))

#Predicting putcome in test data set
test_data$prediction <- predict(predictionModel,newdata = test_data, type ="response")

#Converting probabilities YES and NO into a binary class 50% of probability.
#If predicted probability is 50% or less we classify that prediction as “no: will not purchase the product”. 
#Above 50% probabilities are classified as "yes: will purchase the product".
test_data$binary_prediction<-ifelse(test_data$prediction > 0.5,1,0)
```

```{r}
#Model Accuracy
test_data <- test_data %>% 
  mutate(accurate = 1*(binary_prediction == test_data$Purchase))

accuracy <- sum(test_data$accurate)/nrow(test_data)
print (paste("Accuracy:",round(accuracy,3)))
```

```{r}
#Converting Values to a factors
test_data$binary_prediction<-as.factor(test_data$binary_prediction)
test_data$Purchase<-as.factor(test_data$Purchase)

#Confusion Matrix table
t(confusionMatrix(test_data$binary_prediction,test_data$Purchase)$table)
```

```{r}
#Precision and Recall values
confusionMatrix(test_data$binary_prediction,test_data$Purchase)$byClass
```

```{r}
#ROC Curve
roc_d <- as.data.frame(cbind(test_data$prediction,test_data$Purchase))
basicplot <- ggplot(roc_d, aes(d = V2, m = V1)) + geom_roc(n.cuts = 8, labelsize = 4)
styledplot <- basicplot +
style_roc(xlab = "False Positive Rate", ylab ="True Positive Rate")
styledplot
```


**Gradient Boosted Tree**

```{r}
library(tidymodels)
library(xgboost)
library(vip)
library(DALEXtra)
```

```{r}
#Preparing Data
set.seed(1234)
df$Purchase<-as.factor(df$Purchase)

df$Purchase <- factor(df$Purchase)

data_testtrn <- initial_split(df, prop = 0.7, strata = Purchase)

train.data.GBT <- training(data_testtrn)
test.data.GBT <- testing(data_testtrn)

train.data.GBT$Purchase<-as.factor(train.data.GBT$Purchase)
test.data.GBT$Purchase<-as.factor(test.data.GBT$Purchase)
data_testtrn$Purchase<-as.factor(data_testtrn$Purchase)
```

```{r}
#Model Formulation
rec_purchase <- recipe(Purchase~., train.data.GBT)%>%
  prep(training = train.data.GBT)
rec_purchase
```
```{r}
#Algorithm Type
model_purchase <- boost_tree(
                     trees = tune(),
                     tree_depth = tune(),
                     learn_rate = tune()) %>% 
                     set_engine("xgboost", verbosity = 0) %>% 
                     set_mode("classification")
```

```{r}
#Tuning Hyper parameters
hyper_grid <- grid_regular(
  trees(),
  tree_depth(),
  learn_rate(),
  levels = 4)

#Cross-validation vfold_cv
purchase_folds <- vfold_cv(train.data.GBT, v=5)
```

```{r}
#Aggregating Information to fit the Model
purchase_wf <- workflow() %>%
  add_model(model_purchase) %>%
  add_recipe(rec_purchase)
```

```{r}
#Performing Metrics to get the best model
#doParallel::registerDoParallel(cores = 10)

set.seed(1234)
purchase_tune <- purchase_wf %>% 
  tune_grid(
    resamples = purchase_folds,
    grid = hyper_grid,
    metrics = metric_set(roc_auc)
  ) 

show_best(purchase_tune, metric = "roc_auc", n = 5)


best_model <- purchase_tune %>%
  select_best("roc_auc")
best_model
```
```{r}
#Updating Workflow
final_workflow <- 
  purchase_wf %>% 
  finalize_workflow(best_model)
```

```{r}
#Validate performance on the test data
final_fit <- final_workflow %>%
    last_fit(split = data_testtrn) 

final_fit %>%
  collect_metrics()
```

```{r}
#Plotting which variables played an important role
final_workflow %>%
  fit(data = train.data.GBT) %>%
  extract_fit_parsnip() %>%
  vip(geom = "point")
```

```{r}
#Plot Partial Dependency
model_fitted <- final_workflow %>%
  fit(data = train.data.GBT)
explainer_rf <- explain_tidymodels(model_fitted, 
                                   data = train.data.GBT[,c(-1)],
                                   y = train.data.GBT$Purchase, 
                                   type = "pdp",verbose = FALSE)

pdp_LoyalCH <- model_profile(explainer_rf,
                             variables = "LoyalCH", N=NULL)
pdp_PriceDiff <- model_profile(explainer_rf,
                             variables = "PriceDiff", N=NULL)
pdp_DiscCH <- model_profile(explainer_rf,
                             variables = "DiscCH", N=NULL)

plot(pdp_LoyalCH)
plot(pdp_PriceDiff)
plot(pdp_DiscCH)
```

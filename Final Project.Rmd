---
title: "Final Project"
output: html_document
date: "2022-11-03"
---
```{r}
#Libraries used
library(dplyr)
library(plotROC)
library(ggplot2)
library(caret)
library(performance)
library(car)
library(ROCR)
library(glmnet)
library(corrplot)
library(AICcmodavg)
```

```{r}
#Data set
df<-read.csv(url("http://data.mishra.us/files/project/OJ_data.csv"))
df[2:14] <- lapply(df[2:14], as.numeric)
df$Purchase <- as.factor(df$Purchase)
sapply(df,class)
df
```

```{r}
#Switching Purchase values: 0 to 1 = MM Purchased and 1 to 0 = MM No Purchased.
#A factor with levels 0 and 1 indicating whether the customer purchased Citrus Hill (1) or Minute Maid Orange Juice (0).

df <- df %>%
  mutate(across(Purchase, ~ case_when(. == 0 ~ "Yes",
                                        . == 1 ~ "No",
                                        TRUE ~ NA_character_)))
df <- df %>%
      mutate(Purchase = ifelse(Purchase == "No",0,1))
df
```

```{r}
#Splitting the data into Train, Test
split = 0.7
set.seed(1234)

train.data <- sample(1:nrow(df), split * nrow(df))
test.data <- setdiff(1:nrow(df), train.data)

train.data <- df[train.data,]
test.data <- df[test.data,]
```

```{r}
predictors <- train.data[,c(-1)]
purchase <- train.data$Purchase
```


```{r}
# Checking for multicollinearity and plotting correlations between predictors
correlation = cor(train.data)
correlation
corrplot.mixed(correlation, lower.col = "black", tl.cex=.7,number.cex = .7)
```

```{r}
#Logistic Model
predictionModel <- glm(Purchase ~ ., data = train.data,family=binomial(link='logit'))
summary(predictionModel)

#Dropping predictors variables perfectly correlated
drop <- c("PriceDiff","SalePriceCH", "SalePriceMM", "ListPriceDiff")
train.data = train.data[,!(names(train.data) %in% drop)]

predictionModel <- glm(Purchase ~ ., data = train.data,family=binomial(link='logit'))
summary(predictionModel)

# Calculating VIF for each of the predictors
vif(predictionModel)
```

```{r}
#Examining predictors quality using LASSO
predictors <-data.matrix(predictors)
set.seed(1234)

cv.binomial <- cv.glmnet(x = predictors, y = purchase,
alpha=1, family="binomial",
nfolds=4, standardize = TRUE, type.measure = "auc")
plot(cv.binomial)

#AUC = over 90% of the time the model will classify YES and NO correctly. 
```

```{r}
#Applying shrinkage parameter λ
(best.lambda <- cv.binomial$lambda.min)
y4<- coef(cv.binomial, s="lambda.min", exact=FALSE)
print(y4)
```

```{r}
#Optimal value of λ in the test data
test.predictors <- data.matrix(test.data[,c(-1)])
actual <- test.data$Purchase
pred.model = predict(cv.binomial, newx = test.predictors, type = "response",s ="lambda.min")

pred <- prediction(pred.model, test.data$Purchase)
perf <- performance(pred,"tpr","fpr")
auc_ROCR <- performance(pred,measure ="auc")

# plot ROC curve
plot(perf,colorize=FALSE, col="black") 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
text(1,0.15,labels=paste("AUC = ",round(auc_ROCR@y.values[[1]],
                                        digits=2),sep=""),adj=1)
```
```{r}
#new DF excluding betas less important
drop <- c("PriceCH","PriceMM", "DiscCH", "DiscMM", "SpecialCH", "SalePriceMM","PctDiscMM","ListPriceDiff")
new.df = df[,!(names(df) %in% drop)]
#creating a new DF 
new.df
```
```{r}
#Splitting data
split = 0.7
set.seed(1234)


train_index <- sample(1:nrow(new.df), split * nrow(new.df))
test_index <- setdiff(1:nrow(new.df), train_index)

train_data <- new.df[train_index,]
test_data <- new.df[test_index,]
```

```{r}
#Learning relationship between predictor variables and the outcome variables using train data set
predictionModel <- glm(Purchase ~ ., data = train_data,family=binomial(link='logit'))

#Predicting putcome in test data set
test_data$prediction <- predict(predictionModel,newdata = test_data, type ="response")

#Converting probabilities YES and NO into a binary class 50% of probability.
#If predicted probability is 50% or less we classify that prediction as “no: will not purchase the product”. 
#Above 50% probabilities are classified as "yes: will purchase the product".
test_data$binary_prediction<-ifelse(test_data$prediction > 0.5,1,0)
```

```{r}
#Model Accuracy
test_data <- test_data %>% 
  mutate(accurate = 1*(binary_prediction == test_data$Purchase))

accuracy <- sum(test_data$accurate)/nrow(test_data)
print (paste("Accuracy:",round(accuracy,3)))
```

